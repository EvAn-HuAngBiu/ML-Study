{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 利用朴素贝叶斯实现垃圾邮件分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义文件读取函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "ham_path = r'email/ham/'\n",
    "spam_path = r'email/spam/'\n",
    "\n",
    "def read_email(file_path):\n",
    "    word_list = \"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        line = f.readline().lower()\n",
    "        while line:\n",
    "            word_list += line.lower()\n",
    "            line = f.readline()\n",
    "    # 将换行符替换为空格以便分割\n",
    "    return word_list.replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 读取非垃圾邮件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 正则表达式按非字母、数字分割\n",
    "reg = re.compile('\\\\W+')\n",
    "hams = []\n",
    "for file_name in os.listdir(ham_path):\n",
    "    word = read_email(ham_path + file_name)\n",
    "    # 正则表达式利用非字母、数字进行分割\n",
    "    word_list = reg.split(word)\n",
    "    # 筛选空字符串\n",
    "    hams.append([word for word in word_list if len(word) > 0])\n",
    "len(hams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 读取垃圾邮件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spams = []\n",
    "for file_name in os.listdir(spam_path):\n",
    "    word = read_email(spam_path + file_name)\n",
    "    word_list = reg.split(word)\n",
    "    spams.append([word for word in word_list if len(word) > 0])\n",
    "len(spams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 生成词集和标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "635"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 生成全部邮件的词集\n",
    "word_list = hams + spams\n",
    "# 生成对应标签\n",
    "labels = [0] * len(hams) + [1] * len(spams)\n",
    "# 获取所有词语的集合\n",
    "all_words = set()\n",
    "for w in word_list:\n",
    "    all_words = all_words | set(w)\n",
    "all_words = list(all_words)\n",
    "all_words = {all_words[i] : i for i in range(len(all_words))}\n",
    "len(all_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 统计词频，转换为词向量\n",
    "如果使用伯努利分布，那么在此处，当每个词出现的时候，将词向量中对应位置为1但不递增（即要么是0，要么是1），这样更多考虑的是词与词之间的联系\n",
    "如果使用多项式分布，那么词向量中对应位置可以递增，这样词出现次数对结果的影响将增大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47, 635)\n",
      "(47,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [1, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vec = []\n",
    "for l in word_list:\n",
    "    cur_vec = [0] * len(all_words)\n",
    "    for w in l:\n",
    "        cur_vec[all_words[w]] = 1\n",
    "    word_vec.append(cur_vec)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "word_vec = np.asarray(word_vec)\n",
    "labels = np.asarray(labels)\n",
    "\n",
    "print(word_vec.shape)\n",
    "print(labels.shape)\n",
    "word_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 划分训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 1, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(word_vec, labels, test_size=0.2, stratify=labels)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练模型并预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 0 0 1 1 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 1, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "gnb = BernoulliNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "pred = gnb.predict(X_test)\n",
    "print(pred)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91         5\n",
      "           1       1.00      0.80      0.89         5\n",
      "\n",
      "    accuracy                           0.90        10\n",
      "   macro avg       0.92      0.90      0.90        10\n",
      "weighted avg       0.92      0.90      0.90        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "t = classification_report(y_test, pred, target_names=['0', '1'])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
